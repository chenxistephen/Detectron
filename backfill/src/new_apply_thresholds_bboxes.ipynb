{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelType = HF_Detector===================\n",
      "cls_thrsh_file = /home/chnxi/Detectron/backfill/HF_Detector/class_thresholds_at_pr.pkl===================\n",
      "modelOutBoxFolder = /media/data/chnxi/GOD/threshold_bboxes/HF_Detector===================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "from PIL import Image\n",
    "import pickle as pkl\n",
    "import cv2\n",
    "\n",
    "from detectron.datasets.json_dataset import JsonDataset\n",
    "from detectron.utils.io import load_object, save_object\n",
    "import detectron.utils.vis as vis_utils\n",
    "\n",
    "\n",
    "def checkMkdir(dirname):\n",
    "    if not osp.isdir(dirname):\n",
    "        os.makedirs(dirname)\n",
    "\n",
    "\n",
    "modelType = 'HF_Detector' # 'Fashion_Detector' #'COCO_Mask_Detector'\n",
    "fixedPrec = 0.8\n",
    "\n",
    "outThrshBoxPath = osp.join('/media/data/chnxi/GOD/threshold_bboxes/') #, 'prec_at_{}'.format(fixedPrec))\n",
    "modelOutBoxFolder = osp.join(outThrshBoxPath, modelType)\n",
    "checkMkdir(modelOutBoxFolder)\n",
    "\n",
    "if modelType == 'Fashion_Detector':\n",
    "    cls_thrsh_file = '/home/chnxi/ssd/backfill/data/class_thresholds_at_pr.pkl'\n",
    "    boxesOnDataset = {\n",
    "        #'furniture_train': '/home/chnxi/ssd/backfill/FashionV2_on_HFTrain/outputs/FashionV2_HFTrain_by_image.json',\n",
    "        #'COCO_trainval': '/home/chnxi/ssd/backfill/FashionV2_on_COCOTrainval/outputs/FashionV2_COCOTrainvalBbox_by_image.json',\n",
    "        #'OpenImage_train': '/home/chnxi/ssd/backfill/FashionV2_on_OpenImage/outputs/FashionV2_OpenImageTrain_Bboxes_by_image.json',\n",
    "        'Object365_train': '/home/chnxi/ssd/backfill/FashionV2_on_Object365/outputs/FashionV2_Object365Train_by_image.json',\n",
    "    }\n",
    "elif modelType == 'HF_Detector':\n",
    "    cls_thrsh_file = '/home/chnxi/Detectron/backfill/HF_Detector/class_thresholds_at_pr.pkl'\n",
    "    boxFilePath = '/home/chnxi/Detectron/backfill/HF_Detector/'\n",
    "    boxesOnDataset = {#'FashionV2_train': boxFilePath + 'FashionV2_train/test/FashionV2_train/retinanet/detections.pkl',\n",
    "    #'OpenImage_train': boxFilePath + 'OpenImage_train/test/OpenImage_train/retinanet/detections.pkl', \n",
    "    #'coco_2014_valminusminival':  boxFilePath + 'coco_trainval/test/coco_2014_valminusminival/retinanet/detections.pkl',\n",
    "    #'coco_2014_train': boxFilePath + 'coco_trainval/test/coco_2014_train/retinanet/detections.pkl',\n",
    "    'Object365_train': boxFilePath + 'Object365_train/Object365_train/retinanet/detections.pkl',\n",
    "                     }\n",
    "    \n",
    "elif modelType == 'COCO_Mask_Detector':\n",
    "    cls_thrsh_file = '/home/chnxi/Detectron/backfill/COCO_Mask_Detector/class_thresholds_at_pr.pkl'\n",
    "    boxFilePath = '/home/chnxi/Detectron/backfill/COCO_Mask_Detector/'\n",
    "    boxesOnDataset = {'FashionV2_train': boxFilePath + 'FashionV2_train/test/FashionV2_train/generalized_rcnn/detections.pkl',\n",
    "    'OpenImage_train': boxFilePath + 'OpenImage_train/test/OpenImage_train/generalized_rcnn/detections.pkl', \n",
    "    'furniture_train': boxFilePath + 'furniture_train/test/furniture_train/generalized_rcnn/detections.pkl'\n",
    "                     }\n",
    "\n",
    "    \n",
    "print (\"modelType = {}===================\".format(modelType))\n",
    "print (\"cls_thrsh_file = {}===================\".format(cls_thrsh_file))\n",
    "print (\"modelOutBoxFolder = {}===================\".format(modelOutBoxFolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['prec_at', 'rec_at', 'classes', 'cls_aps'])\n",
      "58\n",
      "[0.53108162 0.40394038 0.49834916 0.58538604 0.55322909 0.50788492\n",
      " 0.41246161 0.46174601 0.61438024 0.589773   0.63669521 0.4913508\n",
      " 0.44736999 0.49898207 0.55152893 0.5989415  0.58256692 0.60671854\n",
      " 0.42294472 0.45957702 0.5237124  0.50280547 0.51417321 0.51839036\n",
      " 0.55527121 0.65307546 0.50789326 0.41195145 0.49644741 0.42217097\n",
      " 0.53769779 0.52608311 0.57853234 0.51026779 0.56736928 0.49196643\n",
      " 0.70769304 0.74092299 0.63649017 0.52677852 0.50551462 0.45433584\n",
      " 0.46677014 0.48081741 0.52257943 0.54792863 0.56537491 0.49752668\n",
      " 0.44553861 0.58268529 0.46840149 0.56965488 0.62115413 0.35948369\n",
      " 0.45514172 0.5713113  0.76778102 0.45063075]\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "cls_thrsh_dict = load_object(cls_thrsh_file)\n",
    "print (cls_thrsh_dict.keys())\n",
    "classes = cls_thrsh_dict['classes']\n",
    "\n",
    "apply_cls_thrsh = cls_thrsh_dict['prec_at'][fixedPrec]\n",
    "\n",
    "print(len(apply_cls_thrsh))\n",
    "print(apply_cls_thrsh)\n",
    "print (len(classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelType == 'Fashion_Detector':\n",
    "    for dataset in boxesOnDataset:\n",
    "        print (\"model = {}, dataset = {}\".format(modelType, dataset))\n",
    "        outBoxFile = osp.join(modelOutBoxFolder, dataset + '.json')\n",
    "        print (\"outBoxFile = {}\".format(outBoxFile))\n",
    "        orgBoxFile = boxesOnDataset[dataset]\n",
    "        print (\"loading {}\".format(orgBoxFile))\n",
    "        dets = json.load(open(orgBoxFile,'r'))\n",
    "        print (\"loaded\")\n",
    "        imgNum = len(dets)\n",
    "        print (\"imgNum = {}\".format(imgNum))\n",
    "        validBoxNum = 0\n",
    "        for ix, entry in enumerate(dets):\n",
    "            img_boxes = entry['boxes']\n",
    "            img_boxes_thrshed = []\n",
    "            for box in img_boxes:\n",
    "                cid = box['category_id'] -1\n",
    "                #print (\"category: {}, cid = {}, thrsh = {}, score = {}\".format(box['category_name'], cid, thresholds[cid], box['score']))\n",
    "                if box['score'] > apply_cls_thrsh[cid]:\n",
    "                    img_boxes_thrshed.append(box)\n",
    "            \n",
    "            dets[ix]['boxes'] = img_boxes_thrshed\n",
    "            if ix % 10000 == 0:\n",
    "                print (dets[ix])\n",
    "            validBoxNum += len(img_boxes_thrshed)\n",
    "        print (\"Total boxNum = {}\".format(validBoxNum))\n",
    "        print (\"saving boxes to {}\".format(outBoxFile))\n",
    "        with open(outBoxFile,'w') as fout:\n",
    "            json.dump(dets, fout)\n",
    "        print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = HF_Detector, dataset = Object365_train\n",
      "outBoxFile = /media/data/chnxi/GOD/threshold_bboxes/HF_Detector/Object365_train.pkl\n",
      "loading /home/chnxi/Detectron/backfill/HF_Detector/Object365_train/Object365_train/retinanet/detections.pkl\n",
      "loaded\n",
      "classNum = 58, imgNum = 608606\n",
      "Total boxNum = 922904\n",
      "saving boxes to /media/data/chnxi/GOD/threshold_bboxes/HF_Detector/Object365_train.pkl\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if modelType in ['HF_Detector', 'COCO_Mask_Detector']:\n",
    "    for dataset in boxesOnDataset:\n",
    "        print (\"model = {}, dataset = {}\".format(modelType, dataset))\n",
    "        outBoxFile = osp.join(modelOutBoxFolder, dataset + '.pkl')\n",
    "        print (\"outBoxFile = {}\".format(outBoxFile))\n",
    "        orgBoxFile = boxesOnDataset[dataset]\n",
    "        print (\"loading {}\".format(orgBoxFile))\n",
    "        dets = load_object(orgBoxFile)\n",
    "        print (\"loaded\")\n",
    "        all_boxes = dets['all_boxes'][1:] # all_boxes[0] is for background\n",
    "        classNum = len(all_boxes)\n",
    "        imgNum = len(all_boxes[0])\n",
    "        print (\"classNum = {}, imgNum = {}\".format(classNum, imgNum))\n",
    "        dataset_thrsh_boxes = [] # in dataset_thrsh_boxes[imgid][cid] format\n",
    "        validBoxNum = 0\n",
    "\n",
    "        for imgid in range(imgNum):\n",
    "            keep_img_boxes = []\n",
    "            for cid in range(classNum):\n",
    "                img_cls_boxes = all_boxes[cid][imgid]\n",
    "                keep_img_cls_boxes = [bbox for bbox in img_cls_boxes if bbox[-1] > apply_cls_thrsh[cid]]\n",
    "                validBoxNum += len(keep_img_cls_boxes)\n",
    "                keep_img_boxes.append(keep_img_cls_boxes)\n",
    "            dataset_thrsh_boxes.append(keep_img_boxes)\n",
    "\n",
    "        print (\"Total boxNum = {}\".format(validBoxNum))\n",
    "        print (\"saving boxes to {}\".format(outBoxFile))\n",
    "        save_object(dataset_thrsh_boxes, outBoxFile)\n",
    "        print (\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
