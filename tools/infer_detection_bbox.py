#!/usr/bin/env python2

# Copyright (c) 2017-present, Facebook, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
##############################################################################

"""Perform inference on a single image or all images with a certain extension
(e.g., .jpg) in a folder.
"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

from collections import defaultdict
import argparse
import cv2  # NOQA (Must import before importing caffe2 due to bug in cv2)
import glob
import logging
import os
import sys
import time

from caffe2.python import workspace

from detectron.core.config import assert_and_infer_cfg
from detectron.core.config import cfg
from detectron.core.config import merge_cfg_from_file
from detectron.utils.io import cache_url
from detectron.utils.timer import Timer
import detectron.core.test_engine as infer_engine
import detectron.datasets.dummy_datasets as dummy_datasets
from detectron.datasets.json_dataset import JsonDataset
import detectron.utils.c2 as c2_utils
import detectron.utils.logging
import detectron.utils.vis as vis_utils
import os.path as osp
import pickle
c2_utils.import_detectron_ops()
# OpenCL may be enabled by default in OpenCV3; disable it because it's not
# thread safe and causes unwanted GPU memory allocations.
cv2.ocl.setUseOpenCL(False)


def parse_args():
    parser = argparse.ArgumentParser(description='End-to-end inference')
    parser.add_argument(
        '--cfg',
        dest='cfg',
        help='cfg model file (/path/to/model_config.yaml)',
        default=None,
        type=str
    )
    parser.add_argument(
        '--wts',
        dest='weights',
        help='weights model file (/path/to/model_weights.pkl)',
        default=None,
        type=str
    )
    parser.add_argument(
        '--output-dir',
        dest='output_dir',
        help='directory for visualization pdfs (default: /tmp/infer_simple)',
        default='/tmp/infer_simple',
        type=str
    )
    parser.add_argument(
        '--pkl_file', dest='pkl_file', default=None, type=str
    )
    parser.add_argument(
        '--image-ext',
        dest='image_ext',
        help='image file name extension (default: jpg)',
        default='jpg',
        type=str
    )
    parser.add_argument(
        '--im_or_folder', dest='im_or_folder', help='image or folder of images', default=None
    )
    parser.add_argument(
        '--im_list', dest='im_list', help='image list of images', default=None
    )
    parser.add_argument(
        '--cls_thrsh_file', dest='cls_thrsh_file', help='image or folder of images', default=None
    )
    parser.add_argument(
        '--thresh',
        dest='thresh',
        help='detection prob thresh1old for all classes',
        default=0.5,
        type=float
    )
    parser.add_argument(
        '--class_list_file',
        dest='class_list_file',
        help='class_list_file',
        default=None,
        type=str
    )
    parser.add_argument(
        '--datasetName', dest='datasetName', help='datasetName', default=None
    )
    parser.add_argument(
        'opts',
        help='See detectron/core/config.py for all options',
        default=None,
        nargs=argparse.REMAINDER
    )
    # if len(sys.argv) == 1:
    #     parser.print_help()
    #     sys.exit(1)
    return parser.parse_args()
    
import numpy as np
def convert_from_cls_format(cls_boxes, cls_segms, cls_keyps):
    """Convert from the class boxes/segms/keyps format generated by the testing
    code.
    """
    box_list = [b for b in cls_boxes if len(b) > 0]
    if len(box_list) > 0:
        boxes = np.concatenate(box_list)
    else:
        boxes = None
    if cls_segms is not None:
        segms = [s for slist in cls_segms for s in slist]
    else:
        segms = None
    if cls_keyps is not None:
        keyps = [k for klist in cls_keyps for k in klist]
    else:
        keyps = None
    classes = []
    for j in range(len(cls_boxes)):
        classes += [j] * len(cls_boxes[j])
    return boxes, segms, keyps, classes
    
def checkMkdir(dir):
    if not osp.isdir(dir):
        os.makedirs(dir)

def extend_results(index, all_res, im_res):
    """Add results for an image to the set of all results at the specified
    index.
    """
    # Skip cls_idx 0 (__background__)
    for cls_idx in range(1, len(im_res)):
        all_res[cls_idx][index] = im_res[cls_idx]

def main(args):
    logger = logging.getLogger(__name__)
    merge_cfg_from_file(args.cfg)
    cfg.NUM_GPUS = 1
    vis = True #False 
    shuffleList = False
    thresh = args.thresh
    dataset = JsonDataset(datasetName) if args.datasetName is not None else None
    classes_list = None
    if args.cls_thrsh_file is not None:
        class_thresholds = {l.split('\t')[0]:float(l.rstrip().split('\t')[1]) for l in open(args.cls_thrsh_file,'r').readlines()}
        print (class_thresholds)
        classes_list = [l.split('\t')[0] for l in open(args.cls_thrsh_file,'r').readlines()]
    else:
        class_thresholds = None
    
    if args.class_list_file is not None:
        classes_list = [l.rstrip().split('\t')[0].split('/')[-1] for l in open(args.class_list_file,'r').readlines()]
        #classes_list = [l.rstrip().split('\t')[0].split('\\')[-1] for l in open(args.class_list_file,'r').readlines()]
    elif dataset is not None:
        classes_list = dataset.classes

    if classes_list is not None:
        classes_list = ['background'] + classes_list
        
    print (classes_list[:10])
    
    args.weights = cache_url(args.weights, cfg.DOWNLOAD_CACHE)
    assert_and_infer_cfg(cache_urls=False)
    model = infer_engine.initialize_model_from_cfg(args.weights)
    

    
    print (args.im_or_folder)
        
    if osp.isdir(args.im_or_folder):
        if args.im_list is None:
            im_list = glob.glob(args.im_or_folder + '/*.' + args.image_ext)
            #im_list = [osp.basename(n) for n in im_list]
        else:
            im_list = [l.rstrip().split('\t')[0].split('.')[0] + '.jpg' for l in open(args.im_list, 'r').readlines()]
            im_list = [osp.join(args.im_or_folder, n) for n in im_list]
            print (im_list[0])

    if shuffleList:
        from random import shuffle
        shuffle(im_list)
        
    checkMkdir(args.output_dir)

    ###################################################
    ## all_boxes: saves all results:
    num_images = len(im_list)
    num_classes = len(classes_list)
    all_boxes = [[[] for _ in range(num_images)] for _ in range(num_classes)]
    print (f"Inference on {num_images} images")
    ###################################################


    for img_id, im_name in enumerate(im_list):
        im = cv2.imread(im_name)
        if im is None:
            print ("{} not exists! continue! ======================".format(im_name))
            continue
        timers = defaultdict(Timer)
        t = time.time()
        with c2_utils.NamedCudaScope(0):
            cls_boxes, cls_segms, cls_keyps = infer_engine.im_detect_all(
                model, im, None, timers=timers
            )
        logger.info('{}: {:.3f}s'.format(im_name, time.time() - t))
        if img_id == 0:
            logger.info(
                ' \ Note: inference on the first image will be slower than the '
                'rest (caches and auto-tuning need to warm up)'
            )
        if (img_id + 1) % 100 == 0:
            print ("{}/{}".format(img_id+1, len(im_list)))
        
        extend_results(img_id, all_boxes, cls_boxes)

        if vis:
            vis_utils.vis_one_image(
                im[:, :, ::-1],
                '{:d}_{:s}'.format(img_id, im_name),
                os.path.join(args.output_dir, 'vis_thrsh_{}'.format(thresh)),
                cls_boxes,
                segms=cls_segms,
                keypoints=cls_keyps,
                thresh=thresh,
                box_alpha=0.8,
                    dataset=dataset,
                show_class=True, 
                ext='png', 
                classes_list=classes_list
            )
    if args.pkl_file is not None:
        print ("Saving all_boxes to {}".format(args.pkl_file))
        with open(args.pkl_file, 'wb') as f:
            pickle.dump(all_boxes, f, 2)


if __name__ == '__main__':
    workspace.GlobalInit(['caffe2', '--caffe2_log_level=0'])
    detectron.utils.logging.setup_logging(__name__)
    args = parse_args()
    ############################################################################################################
    # For debug:
    model_dict = {'HF': {'MODEL_PATH': "Trained_Models/HomeFurniture/V1_Shipping/", "MODEL_NAME": "", 
                          "cfg": "configs/HomeFurniture/hf_fashion_vi_retinanet.yaml", 
                          "class_list": '/media/data/chnxi/HomeFurniture/taxonomy/furniture_58_labels.txt'}, 
                 'GOD': {'MODEL_PATH':'/media/data/chnxi/GOD/Models/', 'MODEL_NAME': 'Final_Candidate', 
                         'cfg':'/media/data/chnxi/GOD/Models/Final_Candidate/retinanet_R-50-FPN_8gpu.yaml', 
                         'class_list': '/media/data/chnxi/GOD/taxonomy/GODv1_May2020_579_Labels_final.txt'},
           'FashionV3': {'MODEL_PATH': "Trained_Models/FashionV3/", "MODEL_NAME": "V3_Shipping", 
                         'cfg': 'Trained_Models/FashionV3/V3_Shipping/fashion_hf_vi_167_retinanet.yaml',
                         'class_list': '/media/data/chnxi/FashionV3/taxonomy/fashion_furniture_visualintent_166_labels.txt'}}
    modelType = 'GOD'
    MODEL_PATH = model_dict[modelType]['MODEL_PATH'] 
    MODEL_NAME = model_dict[modelType]['MODEL_NAME'] 
    args.cfg = model_dict[modelType]['cfg']
    args.class_list_file=  model_dict[modelType]['class_list']
    model_folder = osp.join(MODEL_PATH, MODEL_NAME)
    output_folder = osp.join(model_folder, 'CamV3')
    
    #"configs/GOD/e2e_faster_rcnn_R-50-FPN_8gpu.yaml"
    args.weights= osp.join(model_folder, 'model_final.pkl')
    args.output_dir=osp.join(output_folder, 'visualizations')
    args.pkl_file = osp.join(output_folder, 'all_boxes.pkl')
    args.im_list = '/media/data/chnxi/GOD/IPU/imgs/imglist.txt' #'/media/data/chnxi/CameraMeasurementSetV3/camera_set_v3_imglist.tsv'
    args.im_or_folder='/media/data/chnxi/GOD/IPU/imgs/'
    #'/media/data/chnxi/GOD/taxonomy/GOD_V1.1_labels.txt'
    ############################################################################################################
    print (args)
    main(args)